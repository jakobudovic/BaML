{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Admission\n",
    "\n",
    "Take a look at the data in \"admit-train.csv\". The attribute \"admit\" indicates whether a student has been admitted to a Master's course. The attributes \"gre\" and \"gpa\" contain the results of certain exams. The attribute \"rank\" represents the reputation rank of the student's current university, where smaller ranks correspond to higher reputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data into dataframe\n",
    "df_train = pd.read_csv(\"admit-train.csv\")\n",
    "\n",
    "# Show data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairplot and get an overview of variable dependencies and distributions\n",
    "pd.plotting.scatter_matrix(df_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "\n",
    "Name the dependent variable and the independent variables.  \n",
    "Which scales of measurement do the variables belong to? (e.g. nominal, ordinal, interval or ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "| Variable | Dependent?  | Scale of measurement |\n",
    "| -------- | ----------- | --------------------- |\n",
    "| *\"rank\"* | Independent | Ordinal               |\n",
    "| *\"gre\"*  | Independent | Interval              |\n",
    "| *\"gpa\"*  | Independent | Interval              |\n",
    "| *\"admit\"*| Dependent   | Nominal               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "Use the statsmodels module and train a generalized linear model on the data from \"admit-train.csv\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Mark \"rank\" as categorical\n",
    "df_train[\"rank\"] = df_train[\"rank\"].astype(\"category\")\n",
    "\n",
    "# Define and fit a model\n",
    "logreg = smf.logit(\"admit ~ gre + gpa + rank\", data=df_train)\n",
    "result = logreg.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The categorical variable \"rank\" is represented by three different variables which indicate whether the rank has a certain value:\n",
    "$$\n",
    "rank[T.i] = \\mathbb{I}[rank = i]\n",
    "$$\n",
    "For $rank = 1$, we don't need another variable since this case can be inferred if all other rank-variables are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which coefficients are statistically significant for a level of $\\alpha=0.05$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "For most attributes, the test-statistic $z$ has a p-value (``P > |z|``) which is below $\\alpha$. We can conclude that these attributes are statistically significant at the given signifance level. Only for the attribute ``rank[T.2]``, we cannot reject the null hypothesis $H_0: \\beta_{rank = 2} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)\n",
    "\n",
    "Interpret the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "| Parameter | Value | Interpretation |\n",
    "| --- | --- | --- |\n",
    "| intercept  | -4.8711 | - |\n",
    "| $\\beta_{gre}$ | 0.0031 | As the \"gre\" score increases by one point, the odds of being admitted increase by a factor of 1.003. ($\\exp(0.003) \\approx 1.003$) |\n",
    "| $10 \\cdot \\beta_{gre}$ | 0.0301 | As the \"gre\" score increases by ten points, the odds of being admitted increase by a factor of 1.03. ($\\exp(0.03) \\approx 1.03$) |\n",
    "| $\\beta_{gpa}$ | 0.9204 | As the \"gpa\" score increases by one point, the odds of being admitted increase by a factor of 2.51. ($\\exp(0.92) \\approx 2.51$) |\n",
    "| $\\beta_{rank = 2}$ | -0.6255 | If the rank is 2, the odds of being accepted is lowered by a factor of 0.53 ($\\exp(-0.63) \\approx 0.53$) compared to rank 1. |\n",
    "| $\\beta_{rank = 3}$ | -1.5245 | If the rank is 3, the odds of being accepted is lowered by a factor of 0.22 ($\\exp(-1.52) \\approx 0.22$) compared to rank 1. |\n",
    "| $\\beta_{rank = 4}$ | -1.6853 | If the rank is 4, the odds of being accepted is lowered by a factor of 0.18 ($\\exp(-1.69) \\approx 0.18$) compared to rank 1. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)\n",
    "\n",
    "Test the significance of the attribute \"rank\" by using a Wald test. \n",
    "\n",
    "Is the attribute \"rank\" statistically significant w.r.t. a level of $\\alpha = 5\\%$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the restrictions as a list of strings and pass it to \"r_matrix\"\n",
    "wald_test_result = result.wald_test(\n",
    "  \t\"(rank[T.2] = 0, rank[T.3] = 0, rank[T.4] = 0)\", \n",
    "  \tscalar=True\n",
    ")\n",
    "print(f\"Test statistic (chi^2_{int(wald_test_result.df_denom)}-distributed): {wald_test_result.statistic}\")\n",
    "print(f\"p-value of the statistic: {wald_test_result.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "The attribute is statistically significant since $\\text{p-value} < 5\\%$.  \n",
    "This means that we can reject the null-hypothesis (\"$\\beta_{\\text{rank}}$ = 0\") at a significance level of $\\alpha = 5 \\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e)\n",
    "\n",
    "In order to gain a better understanding of the model, have a look at the predicted probabilities of some data points. Adjust only one parameter and keep the others constant. For example, keep \"gre\" and \"gpa\" constant (mean value), while varying \"rank\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = [1, 2, 3, 4]\n",
    "new_points = pd.DataFrame({\"gre\" : df_train[\"gre\"].mean(),\n",
    "                          \"gpa\" : df_train[\"gpa\"].mean(),\n",
    "                          \"rank\" : rank})\n",
    "\n",
    "new_points[\"predictions\"] = result.predict(new_points)\n",
    "\n",
    "print(new_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f)\n",
    "\n",
    "Find the McFadden ratio and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McFadden Ratio\n",
    "print(result.prsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g)\n",
    "\n",
    "Load the test data from *admit-test.csv* and predict the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "df_test = pd.read_csv(\"admit-test.csv\")\n",
    "\n",
    "# assign proper data type\n",
    "df_test[\"rank\"] = df_test[\"rank\"].astype(\"category\")\n",
    "\n",
    "# make predictions on test data\n",
    "y_pred_test = (result.predict(df_test.drop(columns = [\"admit\"])) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the confusion matrix for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build confusion matrix\n",
    "y_true_test = df_test[\"admit\"]\n",
    "confusion_matrix = pd.crosstab(y_true_test, y_pred_test)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h)\n",
    "\n",
    "Compute the accuracy \n",
    "$$\n",
    "\\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "of your trained model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = (y_true_test == y_pred_test).sum()\n",
    "total_predictions = len(y_true_test)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(\"Accuracy =\", \"{:.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
