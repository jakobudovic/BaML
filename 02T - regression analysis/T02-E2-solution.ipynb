{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Gauss-Markov assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we recommend using `statsmodels`. \n",
    "Unless you haven't already installed it, you can do so by running\n",
    "```bash\n",
    "pip install statsmodels\n",
    "```\n",
    "\n",
    "*Make sure you have activated your `baml-venv` environment before doing so!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gauss-markov.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "\n",
    "We start by using the simple linear regression model\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3\n",
    "$$\n",
    "\n",
    "Using [``sm.OLS``](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html), compute optimal values for the parameters.\n",
    "\n",
    "> Note: You may want to use ``sm.add_constant`` to add values for the intercept.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input data\n",
    "X = sm.add_constant(data[[\"x1\", \"x2\", \"x3\"]])\n",
    "y = data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model with statsmodels\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results using the summary() function\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the model to predict the $y$-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = model.predict(results.params, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the predicted variables vs. the true variables\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for ax, variable_name in zip(axs, [\"x1\", \"x2\", \"x3\"]):\n",
    "    ax.scatter(data[variable_name], data[\"y\"], label=\"Ground truth\")\n",
    "    ax.scatter(data[variable_name], predicted_values, label=\"Model prediction\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "Compute the residuals $e = \\hat{y} - y$ of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = data[\"y\"] - predicted_values\n",
    "# alternatively: residuals = results.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the residuals over the input variables $x_1$ and $x_2$. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(data[\"x1\"], residuals)\n",
    "plt.figure()\n",
    "plt.scatter(data[\"x2\"], residuals)\n",
    "plt.figure()\n",
    "plt.scatter(data[\"x3\"], residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a White test ([`statsmodels.stats.diagnostic.het_white`](https://www.statsmodels.org/dev/generated/statsmodels.stats.diagnostic.het_white.html)), show that we can reject the hypothesis of homoscedastic residuals at an $\\alpha$ level of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "statistic, p_value, _, _ = het_white(residuals, X)\n",
    "print(f\"Value of the null-hypothesis that the residuals are homoscedastic: {statistic}\")\n",
    "print(f\"p-value of the statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)\n",
    "\n",
    "Consider the alternative model\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_1^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the optimal parameter values. You should observe that the $R^2$ value improves drastically over the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input data\n",
    "X = sm.add_constant(data[[\"x1\", \"x2\", \"x3\"]])\n",
    "X[\"x1^2\"] = np.square(X[\"x1\"])\n",
    "y = data[\"y\"]\n",
    "\n",
    "# Fit a linear model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this model gives a very good fit of the data, there is another problem.\n",
    "Use the Variance inflation factor ([`statsmodels.stats.outliers_influence.variance_inflation_factor`](https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html)) to check whether the variables are dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "for index, variable_name in enumerate(X.columns):\n",
    "    if variable_name == \"const\": \n",
    "        continue\n",
    "    print(f\"VIF for variable {variable_name} is {vif(X, index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Check if residuals are now homoscedastic\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "statistic, p_value, _, _ = het_white(results.resid, X)\n",
    "print(f\"Value of the null-hypothesis that the residuals are homoscedastic: {statistic}\")\n",
    "print(f\"p-value of the statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)\n",
    "Consider a third model:\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the optimal parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input data\n",
    "X = sm.add_constant(data[[\"x1\", \"x2\"]])\n",
    "X[\"x1^2\"] = np.square(X[\"x1\"])\n",
    "y = data[\"y\"]\n",
    "\n",
    "# Fit a linear model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model has multicollinear input variables using the VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "for index, variable_name in enumerate(X.columns):\n",
    "    if variable_name == \"const\": \n",
    "        continue\n",
    "    print(f\"VIF for variable {variable_name} is {vif(X, index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model satisfies the homoscedasticity assumption using the White test and an $\\alpha$ level of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "statistic, p_value, _, _ = het_white(results.resid, X)\n",
    "print(f\"Value of the null-hypothesis that the residuals are homoscedastic: {statistic}\")\n",
    "print(f\"p-value of the statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Visualization of the residuals\n",
    "plt.figure()\n",
    "plt.scatter(data[\"x1\"], results.resid)\n",
    "plt.figure()\n",
    "plt.scatter(data[\"x2\"], results.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the predicted variables vs. the true variables\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "for ax, variable_name in zip(axs, [\"x1\", \"x2\", \"x3\"]):\n",
    "    ax.scatter(data[variable_name], data[\"y\"], label=\"Ground truth\")\n",
    "    ax.scatter(data[variable_name], model.predict(results.params, X), label=\"Model prediction\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(variable_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
