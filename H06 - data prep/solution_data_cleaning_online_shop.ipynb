{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Data Cleaning and Analysis\n",
    "\n",
    "In practise, data often comes labeled with codes or extreme abbreviations like \"Schw_Tr_d_Le_en_W\", instead of descriptive column names. Entries are often missing or erroneous, which can introduce errors to machine learning models. Data cleaning serves the purpose of fixing erroneous entries and ensuring the integrity of the dataset, but it does _not_ involve transforming the data in order to prepare it for an algorithm, e.g. via scaling. The exact steps of a data cleaning process depend on the data at hand, but often include making the data humanly interpretable, removing false/incomplete data points, fixing corrupt entries, removing duplicates, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this exercise, only use pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load \"raw_data.csv\" into a dataframe and rename all columns to match _Description_ from Table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df_raw = pd.read_csv(\"raw_data.csv\", sep=\";\")\n",
    "\n",
    "# Rename all attributes to match the _description_ in Table 1\n",
    "df = df_raw.rename(columns={\n",
    "    \"od\" : \"order_date\",\n",
    "    \"dd\" : \"delivery_date\",\n",
    "    \"a6\" : \"salutation\",\n",
    "    \"a7\" : \"date_of_birth\",\n",
    "    \"a8\" : \"state\",\n",
    "    \"a9\" : \"return_shipment\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Correct the data types for all _nominal_ attributes and assign the corresponding labels that are specified under _Comment_ in Table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are multiple ways to to this. We use pd.DataFrame.replace() and pass a dict to it\n",
    "\n",
    "df[\"salutation\"] = df[\"salutation\"].replace({\n",
    "    2 : \"Company\",\n",
    "    3 : \"Mr.\",\n",
    "    4 : \"Mrs.\"}).astype(\"category\")\n",
    "\n",
    "df[\"state\"] = df[\"state\"].replace({\n",
    "    1 : \"BW\",\n",
    "    2 : \"BY\",\n",
    "    3 : \"BE\",\n",
    "    4 : \"BB\",\n",
    "    5 : \"HB\",\n",
    "    6 : \"HH\",\n",
    "    7 : \"HE\",\n",
    "    8 : \"MV\",\n",
    "    9 : \"NI\",\n",
    "    10 : \"NW\",\n",
    "    11 : \"RP\",\n",
    "    12 : \"SL\",\n",
    "    13 : \"SN\",\n",
    "    14 : \"ST\",\n",
    "    15 : \"SH\",\n",
    "    16 : \"TH\"}).astype(\"category\")\n",
    "\n",
    "df[\"return_shipment\"] = df[\"return_shipment\"].replace({\n",
    "  0 : \"No\",\n",
    "  1 : \"Yes\"}).astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Correct the data type of the _ordinal_ attribute \"size\" and assign the corresponding labels specified under _Comment_ in Table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to fix case-sensitivity, otherwise there will be distinct categories created for every different case\n",
    "df[\"size\"] = df[\"size\"].astype(\"str\").str.upper()  \n",
    "df[\"size\"] = pd.Series(pd.Categorical(df[\"size\"], categories=[\"S\", \"M\", \"L\", \"XL\", \"XXL\", \"XXXL\"], ordered=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Correct the data types for all _date_ attributes. Split \"order_date\" into separate columns for \"weekday\", \"year\", \"month\", \"day\" and \"quarter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas Datetime format for this. Pass errors=\"coerce\" to convert erroneous values into NaT (not a time)\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"])\n",
    "df[\"delivery_date\"] = pd.to_datetime(df[\"delivery_date\"], errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "df[\"date_of_birth\"] = pd.to_datetime(df[\"date_of_birth\"], errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "\n",
    "# Make separate columns for order_date\n",
    "df[\"order_date_weekday\"] = df[\"order_date\"].dt.dayofweek\n",
    "df[\"order_date_day\"] = df[\"order_date\"].dt.day\n",
    "df[\"order_date_month\"] = df[\"order_date\"].dt.month\n",
    "df[\"order_date_year\"] = df[\"order_date\"].dt.year\n",
    "df[\"order_date_quarter\"] = df[\"order_date\"].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Find missing values (NaN, NaT, None), remove or fill these entries (e.g. by mean).\n",
    "\n",
    "To deal with missing values adequately, it is important to understand what type of data is at hand, and why it is missing. For example, if the date of birth of a customer is not specified, the data point might still contain valuable information about the customer's orders, and it would be a waste to remove the complete data point. In such cases, it can make sense to keep the value as NaN or introduce a default value which makes it apparent that this value was missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, locate the columns that have at least one missing value (None, NaN, NaT, and similar).\n",
    "print(df.isna().any())  # -> delivery_date, price, tax, date_of_birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill \"price\" and \"tax\" with their column means.\n",
    "means = {\"price\" : df[\"price\"].mean(), \"tax\" : df[\"tax\"].mean()}\n",
    "df = df.fillna(value=means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing \"delivery_date\" entries.\n",
    "df = df.dropna(subset=[\"delivery_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the data is essentially clean, perform some basic analysis on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Create a new column for \"delivery_time\" as the difference of \"delivery_date\" and \"order_date\". Inspect the created column for errors and label erroneous entries accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning to a new column name will automatically create it\n",
    "# Pandas supports strucure operations, so simply subtracting columns from each other works\n",
    "# Access the amount of days via the datetime accessor of the datetime object (.dt.days)\n",
    "df[\"delivery_time_days\"] = (df[\"delivery_date\"] - df[\"order_date\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.where() replaces values where the specified condition is False\n",
    "df[\"delivery_time_days\"] = df[\"delivery_time_days\"].where(df[\"delivery_time_days\"] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Plot a histogram for the new \"delivery_time_days\" column. Then discretize its values into the bins \"NaN\", \"<=5d\", and \">5d\" and store these in a new column \"delivery_time_days_discrete\". Plot a bar chart for \"delivery_time_days_discrete\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "df[\"delivery_time_days\"].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize using pd.cut(), NaN values will be binned into NaN category by default\n",
    "max_time = df[\"delivery_time_days\"].max()\n",
    "df[\"delivery_time_days_discrete\"] = pd.cut(df[\"delivery_time_days\"], \n",
    "                                           bins=[0, 5, max_time], \n",
    "                                           labels=[\"<=5d\", \">5d\"])\n",
    "df[\"delivery_time_days_discrete\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart\n",
    "df[\"delivery_time_days_discrete\"].value_counts(sort=False).plot.bar(color=[\"green\", \"orange\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Compute the correlation matrix for the numerical attributes. Plot the matrix of the scatterplots. Plot the heatmap of the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of dataframe\n",
    "corr = df.corr(numeric_only=True)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter matrix\n",
    "matrix_of_scatter_plots = pd.plotting.scatter_matrix(df, figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix of standardized data\n",
    "df_only_numerical = df.select_dtypes(include=\"number\")\n",
    "df_normalized = (df_only_numerical - df_only_numerical.mean()) / df_only_numerical.std()\n",
    "corr_normalized = df_normalized.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Corporate needs you to find the differences between corr matrix and corr_normalized matrix.\")\n",
    "\n",
    "difference = corr - corr_normalized\n",
    "if (difference < 1e-8).all().all():\n",
    "    print(\"--> They're the same matrix.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
